{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of Mixture Proportion Estimation using Kernel Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "DO MIXTURE PROPORTION ESTIMATION \n",
    "Using gradient thresholding of the $\\C_S$-distance\n",
    "\"\"\"\n",
    "from cvxopt import matrix, solvers, spmatrix\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.close('all')\n",
    "import scipy.linalg as scilin\n",
    "from Kernel_MPE_grad_threshold import *\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import time\n",
    "np.random.seed(seed=12342)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, I generate two datasets. The first is the mixture, composed of $(1-\\kappa^*)$ proportion of observations with `size` number of covariates from the standard normal distribution and $\\kappa^*$ proportion of observations with `size` number of covariates from a shifted standard normal distribution. The second dataset is the component, composed only of observations with covariates from the shifted standard normal distribution. For our problem, the mixture is the Iowa patient dataset while the component is the Wisconsin patient dataset.\n",
    "\n",
    "After the data is generated, we call the MPE code using the two different thresholding techniques and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7105e57e5454>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmean_comp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMPE_sim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_observations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkappa_star\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_comp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Kappa* = \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkappa_star\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-7105e57e5454>\u001b[0m in \u001b[0;36mMPE_sim\u001b[1;34m(total_observations, kappa_star, size, mean_comp)\u001b[0m\n\u001b[0;32m      7\u001b[0m                                 mean_comp))\n\u001b[0;32m      8\u001b[0m     \u001b[0mX_component\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_observations\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmean_comp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mKM1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mKM2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_mixture\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_component\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mKM1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mKM2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "def MPE_sim(total_observations, kappa_star, size, mean_comp):\n",
    "    \"\"\" Calls wrapper with a GMM as the mixture distribution and one of the \n",
    "    components as the component distribution. Replace the X_mixture and X_component \n",
    "    variables according to your data\"\"\"\n",
    "    X_mixture = np.concatenate((np.random.randn(int((1-kappa_star)*total_observations/2), size), \n",
    "                                np.random.randn(int(kappa_star*total_observations/2), size)+\n",
    "                                mean_comp))\n",
    "    X_component = np.random.randn(int(total_observations/2), size) + mean_comp\n",
    "    (KM1,KM2)=wrapper(X_mixture,X_component)\n",
    "    return KM1,KM2\n",
    "    \n",
    "total_observations = 500\n",
    "kappa_star = 0.4\n",
    "size = 100\n",
    "mean_comp = np.repeat(10.,size)\n",
    "pred = MPE_sim(total_observations, kappa_star, size, mean_comp)\n",
    "    \n",
    "print(\"Kappa* = \",kappa_star)\n",
    "print(\"Observations = \",total_observations)\n",
    "print(\"Covariates = \",size)\n",
    "print(\"KM1_estimate = \",pred[0])\n",
    "print(\"KM2_estimate = \",pred[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the toy example, we see that when the target population is *much* different from the other component (henceforth called unrelated component) in the mixture, our algorithm does a very good job at approximating the true mixture proportion. \n",
    "\n",
    "However, what happens as we deviate from this simple case? Let's simulate the number of observations, the true mixture proportion, the number of covariates, and the separation between the target population and unrelated component. I will run 10,000 simulations and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create numpy array to store results\n",
    "results = np.zeros((125,8))\n",
    "\n",
    "#Run 1000 simulations for total_observation change\n",
    "for i in range(0,125):\n",
    "    if (i % 250) == 0:\n",
    "        print(\"Simulation: \",i)\n",
    "    results[i,0] = total_observations = 2*(i+5)\n",
    "    results[i,1] = kappa_star = 0.4\n",
    "    results[i,2] = size = 100\n",
    "    mean_comp = np.repeat(10.,size)\n",
    "    pred = MPE_sim(total_observations, kappa_star, size, mean_comp)\n",
    "    results[i,3] = np.mean(mean_comp)\n",
    "    results[i,4] = pred[0]\n",
    "    results[i,5] = pred[1]    \n",
    "    \n",
    "#Calculate absolute error for each simulation, thresholding technique\n",
    "results[:,6] = abs(results[:,1]-results[:,4])\n",
    "results[:,7] = abs(results[:,1]-results[:,5])\n",
    "\n",
    "#Generate a pandas dataframe\n",
    "obs_results = pd.DataFrame(data = results, columns = ['total_observations', 'kappa_star', 'size','mean_comp','KM1','KM2','KM1_error','KM2_error'])\n",
    "\n",
    "#Save results\n",
    "obs_results.to_csv('results/obs_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create numpy array to store results\n",
    "results = np.zeros((250,8))\n",
    "\n",
    "#Create values for kappa\n",
    "x = np.linspace(0.10,0.90,250)\n",
    "\n",
    "#Run 1000 simulations for kappa_star change\n",
    "for i in range(0,250):\n",
    "    if (i % 250) == 0:\n",
    "        print(\"Simulation: \",i)\n",
    "    results[i,0] = total_observations = 500\n",
    "    results[i,1] = kappa_star = x[i]\n",
    "    results[i,2] = size = 100\n",
    "    mean_comp = np.repeat(10.,size)\n",
    "    pred = MPE_sim(total_observations, kappa_star, size, mean_comp)\n",
    "    results[i,3] = np.mean(mean_comp)\n",
    "    results[i,4] = pred[0]\n",
    "    results[i,5] = pred[1]    \n",
    "    \n",
    "#Calculate absolute error for each simulation, thresholding technique\n",
    "results[:,6] = abs(results[:,1]-results[:,4])\n",
    "results[:,7] = abs(results[:,1]-results[:,5])\n",
    "\n",
    "#Generate a pandas dataframe\n",
    "kappa_results = pd.DataFrame(data = results, columns = ['total_observations', 'kappa_star', 'size','mean_comp','KM1','KM2','KM1_error','KM2_error'])\n",
    "\n",
    "#Save results\n",
    "kappa_results.to_csv('results/kappa_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create numpy array to store results\n",
    "results = np.zeros((150,8))\n",
    "\n",
    "#Run 1000 simulations for kappa_star change\n",
    "for i in range(0,150):\n",
    "    if (i % 125) == 0:\n",
    "        print(\"Simulation: \",i)\n",
    "    results[i,0] = total_observations = 500\n",
    "    results[i,1] = kappa_star = 0.4\n",
    "    results[i,2] = size = (i+2)\n",
    "    mean_comp = np.repeat(10.,size)\n",
    "    pred = MPE_sim(total_observations, kappa_star, size, mean_comp)\n",
    "    results[i,3] = np.mean(mean_comp)\n",
    "    results[i,4] = pred[0]\n",
    "    results[i,5] = pred[1]    \n",
    "    \n",
    "#Calculate absolute error for each simulation, thresholding technique\n",
    "results[:,6] = abs(results[:,1]-results[:,4])\n",
    "results[:,7] = abs(results[:,1]-results[:,5])\n",
    "\n",
    "#Generate a pandas dataframe\n",
    "covariate_results = pd.DataFrame(data = results, columns = ['total_observations', 'kappa_star', 'size','mean_comp','KM1','KM2','KM1_error','KM2_error'])\n",
    "\n",
    "#Save results\n",
    "covariate_results.to_csv('results/covariate_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create numpy array to store results\n",
    "results = np.zeros((250,8))\n",
    "x = np.linspace(1,10,250)\n",
    "\n",
    "#Run 1000 simulations for kappa_star change\n",
    "for i in range(0,250):\n",
    "    if (i % 250) == 0:\n",
    "        print(\"Simulation: \",i)\n",
    "    results[i,0] = total_observations = 500\n",
    "    results[i,1] = kappa_star = 0.4\n",
    "    results[i,2] = 100\n",
    "    c = x[i]\n",
    "    mean_comp = np.repeat(c,size)\n",
    "    pred = MPE_sim(total_observations, kappa_star, size, mean_comp)\n",
    "    results[i,3] = np.mean(mean_comp)\n",
    "    results[i,4] = pred[0]\n",
    "    results[i,5] = pred[1]    \n",
    "    \n",
    "#Calculate absolute error for each simulation, thresholding technique\n",
    "results[:,6] = abs(results[:,1]-results[:,4])\n",
    "results[:,7] = abs(results[:,1]-results[:,5])\n",
    "\n",
    "#Generate a pandas dataframe\n",
    "distance_results = pd.DataFrame(data = results, columns = ['total_observations', 'kappa_star', 'size','mean_comp','KM1','KM2','KM1_error','KM2_error'])\n",
    "\n",
    "#Save results\n",
    "distance_results.to_csv('results/distance_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the results of our simulations\n",
    "def make_plots(data, xvar, xlab):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 3), sharey = True)\n",
    "    axes[0].scatter(data[xvar],data['KM1_error'])\n",
    "    axes[0].title.set_text('KM1')\n",
    "    axes[1].scatter(data[xvar],data['KM2_error'], color = \"Green\")\n",
    "    axes[1].title.set_text('KM2')\n",
    "    axes[0].set(ylabel = 'Absolute Error')\n",
    "    for ax in axes.flat:\n",
    "        ax.set(xlabel=xlab)\n",
    "    fig.tight_layout()\n",
    "    return\n",
    "\n",
    "make_plots(obs_results,'total_observations','Total Observations')\n",
    "make_plots(kappa_results,'kappa_star','Kappa Star')\n",
    "make_plots(covariate_results,'size','Number of Covariates')\n",
    "make_plots(distance_results,'mean_comp','Mean of Component Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runtime analysis for number of observations\n",
    "kappa_star = 0.4\n",
    "size = 100\n",
    "mean_comp = np.repeat(10.,size)\n",
    "results = np.zeros((45,2))\n",
    "    \n",
    "for i in range(0,45):\n",
    "    results[i,0] = total_observations = 500+(i*100)\n",
    "    start_time = time.time()\n",
    "    pred = MPE_sim(total_observations, kappa_star, size, mean_comp)  \n",
    "    results[i,1] = end_time = time.time() - start_time\n",
    "    print(\"Nobs:\",total_observations,\" Runtime: \", end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runtime analysis for number of covariates\n",
    "kappa_star = 0.4\n",
    "total_observations = 1000\n",
    "results2 = np.zeros((45,2))\n",
    "    \n",
    "print(\"Covariates,Runtime\")\n",
    "for i in range(0,45):\n",
    "    results2[i,0] = size = 100+(i*25)\n",
    "    mean_comp = np.repeat(10.,size)\n",
    "    start_time = time.time()\n",
    "    pred = MPE_sim(total_observations, kappa_star, size, mean_comp)  \n",
    "    results2[i,1] = end_time = time.time() - start_time\n",
    "    print(size,\",\", end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results\n",
    "runtime_obs_results = pd.DataFrame(data = results, columns = ['total_observations', 'runtime'])\n",
    "runtime_obs_results.to_csv('results/runtime_obs_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results\n",
    "runtime_cov_results = pd.DataFrame(data = results2, columns = ['size', 'runtime'])\n",
    "runtime_cov_results.to_csv('results/runtime_cov_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot results\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 3), sharey = False)\n",
    "axes[0].scatter(runtime_obs_results['total_observations'],runtime_obs_results['runtime'])\n",
    "axes[0].title.set_text('Runtime vs. Total Observations')\n",
    "axes[1].scatter(runtime_cov_results['size'],runtime_cov_results['runtime'], color = \"Green\")\n",
    "axes[1].title.set_text('Runtime vs. Number of Covariates')\n",
    "axes[0].set(ylabel = 'Runtime (s)', xlabel = 'Total Observations')\n",
    "axes[1].set(xlabel = \"Number of Covariates\", ylim = (0,15))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7e882948ddcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnsim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mid_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mKM2_vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\2019fall\\STAT771\\project\\code\\Kernel_MPE_grad_threshold.py\u001b[0m in \u001b[0;36mid_example\u001b[1;34m(total_observations, kappa_star, size, mean_comp)\u001b[0m\n\u001b[0;32m    175\u001b[0m                                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkappa_star\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtotal_observations\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                                 mean_comp))\n\u001b[1;32m--> 177\u001b[1;33m     \u001b[0mX_component\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_observations\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mmean_comp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mKM1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mKM2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msolution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_mixture\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_component\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.randn\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.standard_normal\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.cont0_array\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "#Identification studies\n",
    "total_observations = 1000\n",
    "kappa_star = 0.4\n",
    "size = 100\n",
    "nsim = 100\n",
    "KM2_vec = np.zeros(nsim)\n",
    "error_vec = np.zeros(nsim)\n",
    "\n",
    "for sim in range(nsim):\n",
    "    KM2_vec[sim], x = id_example(total_observations = total_observations\n",
    "                                , kappa_star = kappa_star\n",
    "                                , size = size)\n",
    "    error_vec[sim] = float(sum(x[0] > ((1-kappa_star)*total_observations/2)))/(kappa_star*total_observations/2)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
